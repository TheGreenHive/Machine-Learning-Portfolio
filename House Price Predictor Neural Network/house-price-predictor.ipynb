{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
      "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
      "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
      "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./kc_house_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data = data.dropna(axis=0)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set y and X values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"price\"].astype(np.float32)\n",
    "data_prediction_features = [\"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\", \"floors\", \"waterfront\", \"view\", \"condition\", \"grade\", \"sqft_above\", \"sqft_basement\", \"yr_built\"]\n",
    "X = data[data_prediction_features].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 10:13:48.077818: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4), # add various dropout layers to prevent overfitting\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Regression task, so no activation function (linear activation)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "# ues adam optimizer function for dynamically updating gradient descent.\n",
    "optimizerFunction = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0005,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.995,\n",
    "    epsilon=5e-06,\n",
    "    amsgrad=True,\n",
    "    name='Adam',\n",
    ")\n",
    "model.compile(optimizer=optimizerFunction,\n",
    "              loss=loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 258208055296.0000 - val_loss: 61297631232.0000\n",
      "Epoch 2/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 61170601984.0000 - val_loss: 47409180672.0000\n",
      "Epoch 3/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 52235173888.0000 - val_loss: 41103679488.0000\n",
      "Epoch 4/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 47441559552.0000 - val_loss: 38896726016.0000\n",
      "Epoch 5/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 47226023936.0000 - val_loss: 38121553920.0000\n",
      "Epoch 6/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 46381244416.0000 - val_loss: 37458554880.0000\n",
      "Epoch 7/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 45331365888.0000 - val_loss: 37547237376.0000\n",
      "Epoch 8/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 45238206464.0000 - val_loss: 37322747904.0000\n",
      "Epoch 9/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 46545018880.0000 - val_loss: 37018673152.0000\n",
      "Epoch 10/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 45107347456.0000 - val_loss: 36849979392.0000\n",
      "Epoch 11/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 45344772096.0000 - val_loss: 36558327808.0000\n",
      "Epoch 12/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 44865118208.0000 - val_loss: 36657840128.0000\n",
      "Epoch 13/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 43930157056.0000 - val_loss: 36448182272.0000\n",
      "Epoch 14/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 44772306944.0000 - val_loss: 36484341760.0000\n",
      "Epoch 15/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 44557488128.0000 - val_loss: 36305117184.0000\n",
      "Epoch 16/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43649617920.0000 - val_loss: 36102094848.0000\n",
      "Epoch 17/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 44258353152.0000 - val_loss: 36319776768.0000\n",
      "Epoch 18/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43615334400.0000 - val_loss: 35963740160.0000\n",
      "Epoch 19/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 44235554816.0000 - val_loss: 36027097088.0000\n",
      "Epoch 20/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 43547529216.0000 - val_loss: 36213350400.0000\n",
      "Epoch 21/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43969019904.0000 - val_loss: 36033462272.0000\n",
      "Epoch 22/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43537477632.0000 - val_loss: 35872325632.0000\n",
      "Epoch 23/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43154960384.0000 - val_loss: 35834654720.0000\n",
      "Epoch 24/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43327807488.0000 - val_loss: 35763523584.0000\n",
      "Epoch 25/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43222736896.0000 - val_loss: 35932282880.0000\n",
      "Epoch 26/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43399852032.0000 - val_loss: 35784478720.0000\n",
      "Epoch 27/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42034462720.0000 - val_loss: 35964071936.0000\n",
      "Epoch 28/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42824695808.0000 - val_loss: 35805454336.0000\n",
      "Epoch 29/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41922093056.0000 - val_loss: 35483619328.0000\n",
      "Epoch 30/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42402766848.0000 - val_loss: 35519238144.0000\n",
      "Epoch 31/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42466672640.0000 - val_loss: 35673100288.0000\n",
      "Epoch 32/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42486812672.0000 - val_loss: 35755556864.0000\n",
      "Epoch 33/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41674534912.0000 - val_loss: 35577315328.0000\n",
      "Epoch 34/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41776365568.0000 - val_loss: 35639554048.0000\n",
      "Epoch 35/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42226712576.0000 - val_loss: 35387162624.0000\n",
      "Epoch 36/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42480971776.0000 - val_loss: 35465043968.0000\n",
      "Epoch 37/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42582618112.0000 - val_loss: 35500290048.0000\n",
      "Epoch 38/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42030186496.0000 - val_loss: 35271815168.0000\n",
      "Epoch 39/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42310504448.0000 - val_loss: 35308933120.0000\n",
      "Epoch 40/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42931728384.0000 - val_loss: 35511283712.0000\n",
      "Epoch 41/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41153667072.0000 - val_loss: 35461029888.0000\n",
      "Epoch 42/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41953210368.0000 - val_loss: 35352944640.0000\n",
      "Epoch 43/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41995489280.0000 - val_loss: 35170787328.0000\n",
      "Epoch 44/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41817444352.0000 - val_loss: 35240062976.0000\n",
      "Epoch 45/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42778705920.0000 - val_loss: 35201191936.0000\n",
      "Epoch 46/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41642201088.0000 - val_loss: 35391737856.0000\n",
      "Epoch 47/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41271083008.0000 - val_loss: 35072921600.0000\n",
      "Epoch 48/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41128456192.0000 - val_loss: 35198238720.0000\n",
      "Epoch 49/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42077089792.0000 - val_loss: 35122757632.0000\n",
      "Epoch 50/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41997275136.0000 - val_loss: 35194941440.0000\n",
      "Epoch 51/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42198798336.0000 - val_loss: 35242270720.0000\n",
      "Epoch 52/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41554948096.0000 - val_loss: 35103735808.0000\n",
      "Epoch 53/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41436778496.0000 - val_loss: 35171729408.0000\n",
      "Epoch 54/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41493438464.0000 - val_loss: 35285266432.0000\n",
      "Epoch 55/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41593667584.0000 - val_loss: 35054739456.0000\n",
      "Epoch 56/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40593420288.0000 - val_loss: 35001974784.0000\n",
      "Epoch 57/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41636257792.0000 - val_loss: 35105230848.0000\n",
      "Epoch 58/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42333499392.0000 - val_loss: 35040985088.0000\n",
      "Epoch 59/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41542623232.0000 - val_loss: 35093745664.0000\n",
      "Epoch 60/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41766371328.0000 - val_loss: 35050016768.0000\n",
      "Epoch 61/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40674926592.0000 - val_loss: 34881724416.0000\n",
      "Epoch 62/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41194287104.0000 - val_loss: 34901942272.0000\n",
      "Epoch 63/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41650745344.0000 - val_loss: 35654598656.0000\n",
      "Epoch 64/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41710358528.0000 - val_loss: 34915041280.0000\n",
      "Epoch 65/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42493108224.0000 - val_loss: 35060645888.0000\n",
      "Epoch 66/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40468717568.0000 - val_loss: 34875342848.0000\n",
      "Epoch 67/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40899866624.0000 - val_loss: 35350048768.0000\n",
      "Epoch 68/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41105387520.0000 - val_loss: 35194802176.0000\n",
      "Epoch 69/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41209090048.0000 - val_loss: 34918363136.0000\n",
      "Epoch 70/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40792248320.0000 - val_loss: 34981273600.0000\n",
      "Epoch 71/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40074088448.0000 - val_loss: 35055542272.0000\n",
      "Epoch 72/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41956368384.0000 - val_loss: 34953793536.0000\n",
      "Epoch 73/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40853069824.0000 - val_loss: 35385315328.0000\n",
      "Epoch 74/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41224990720.0000 - val_loss: 34804617216.0000\n",
      "Epoch 75/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41804201984.0000 - val_loss: 35129565184.0000\n",
      "Epoch 76/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41126694912.0000 - val_loss: 35071479808.0000\n",
      "Epoch 77/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40260960256.0000 - val_loss: 35617447936.0000\n",
      "Epoch 78/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40194596864.0000 - val_loss: 35061215232.0000\n",
      "Epoch 79/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41473679360.0000 - val_loss: 34668716032.0000\n",
      "Epoch 80/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41614573568.0000 - val_loss: 34792325120.0000\n",
      "Epoch 81/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41684025344.0000 - val_loss: 34861092864.0000\n",
      "Epoch 82/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41260523520.0000 - val_loss: 34882727936.0000\n",
      "Epoch 83/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40956977152.0000 - val_loss: 34653843456.0000\n",
      "Epoch 84/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40453607424.0000 - val_loss: 34622181376.0000\n",
      "Epoch 85/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40867348480.0000 - val_loss: 34571386880.0000\n",
      "Epoch 86/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40617746432.0000 - val_loss: 34700476416.0000\n",
      "Epoch 87/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40730300416.0000 - val_loss: 34562392064.0000\n",
      "Epoch 88/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40938475520.0000 - val_loss: 35375263744.0000\n",
      "Epoch 89/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41043107840.0000 - val_loss: 35015139328.0000\n",
      "Epoch 90/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40810082304.0000 - val_loss: 34849349632.0000\n",
      "Epoch 91/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39739432960.0000 - val_loss: 34748846080.0000\n",
      "Epoch 92/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40473509888.0000 - val_loss: 34720239616.0000\n",
      "Epoch 93/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40105639936.0000 - val_loss: 34593841152.0000\n",
      "Epoch 94/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40757293056.0000 - val_loss: 34724573184.0000\n",
      "Epoch 95/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40739229696.0000 - val_loss: 35028443136.0000\n",
      "Epoch 96/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40698945536.0000 - val_loss: 34694213632.0000\n",
      "Epoch 97/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40995250176.0000 - val_loss: 34624278528.0000\n",
      "Epoch 98/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41241882624.0000 - val_loss: 34527330304.0000\n",
      "Epoch 99/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40693022720.0000 - val_loss: 34520530944.0000\n",
      "Epoch 100/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40918740992.0000 - val_loss: 34613321728.0000\n",
      "Epoch 101/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40076161024.0000 - val_loss: 34489827328.0000\n",
      "Epoch 102/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40372727808.0000 - val_loss: 34629378048.0000\n",
      "Epoch 103/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40315908096.0000 - val_loss: 34498932736.0000\n",
      "Epoch 104/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39752306688.0000 - val_loss: 34508779520.0000\n",
      "Epoch 105/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39481208832.0000 - val_loss: 34987323392.0000\n",
      "Epoch 106/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40506691584.0000 - val_loss: 34512986112.0000\n",
      "Epoch 107/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40377237504.0000 - val_loss: 34525487104.0000\n",
      "Epoch 108/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40898031616.0000 - val_loss: 34533486592.0000\n",
      "Epoch 109/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40094494720.0000 - val_loss: 36562665472.0000\n",
      "Epoch 110/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39514517504.0000 - val_loss: 34405642240.0000\n",
      "Epoch 111/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40463421440.0000 - val_loss: 34630496256.0000\n",
      "Epoch 112/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39512276992.0000 - val_loss: 34563166208.0000\n",
      "Epoch 113/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40462147584.0000 - val_loss: 34425552896.0000\n",
      "Epoch 114/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40613990400.0000 - val_loss: 34375671808.0000\n",
      "Epoch 115/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40037474304.0000 - val_loss: 34267060224.0000\n",
      "Epoch 116/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39283277824.0000 - val_loss: 34613964800.0000\n",
      "Epoch 117/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40825860096.0000 - val_loss: 34687266816.0000\n",
      "Epoch 118/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39415955456.0000 - val_loss: 34538967040.0000\n",
      "Epoch 119/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39849684992.0000 - val_loss: 34388520960.0000\n",
      "Epoch 120/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40659177472.0000 - val_loss: 34333243392.0000\n",
      "Epoch 121/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39451803648.0000 - val_loss: 34560262144.0000\n",
      "Epoch 122/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39647756288.0000 - val_loss: 34227611648.0000\n",
      "Epoch 123/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40087810048.0000 - val_loss: 34273882112.0000\n",
      "Epoch 124/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39441317888.0000 - val_loss: 34257195008.0000\n",
      "Epoch 125/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40312311808.0000 - val_loss: 34251243520.0000\n",
      "Epoch 126/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40120086528.0000 - val_loss: 34409889792.0000\n",
      "Epoch 127/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39515189248.0000 - val_loss: 34567094272.0000\n",
      "Epoch 128/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40062963712.0000 - val_loss: 34267619328.0000\n",
      "Epoch 129/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39896670208.0000 - val_loss: 34957041664.0000\n",
      "Epoch 130/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40517926912.0000 - val_loss: 34157449216.0000\n",
      "Epoch 131/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39637958656.0000 - val_loss: 34452328448.0000\n",
      "Epoch 132/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40285224960.0000 - val_loss: 34242824192.0000\n",
      "Epoch 133/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39902650368.0000 - val_loss: 34307702784.0000\n",
      "Epoch 134/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39840747520.0000 - val_loss: 34252013568.0000\n",
      "Epoch 135/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39604203520.0000 - val_loss: 34261993472.0000\n",
      "Epoch 136/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40003629056.0000 - val_loss: 34586365952.0000\n",
      "Epoch 137/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39378575360.0000 - val_loss: 34203394048.0000\n",
      "Epoch 138/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39942643712.0000 - val_loss: 34215743488.0000\n",
      "Epoch 139/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39462658048.0000 - val_loss: 34146324480.0000\n",
      "Epoch 140/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39058599936.0000 - val_loss: 34376978432.0000\n",
      "Epoch 141/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39658336256.0000 - val_loss: 34073128960.0000\n",
      "Epoch 142/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39666200576.0000 - val_loss: 34105174016.0000\n",
      "Epoch 143/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39490453504.0000 - val_loss: 34231789568.0000\n",
      "Epoch 144/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39414927360.0000 - val_loss: 33945053184.0000\n",
      "Epoch 145/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39742418944.0000 - val_loss: 34237280256.0000\n",
      "Epoch 146/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40206872576.0000 - val_loss: 34091890688.0000\n",
      "Epoch 147/150\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40054616064.0000 - val_loss: 34006028288.0000\n",
      "Epoch 148/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40087736320.0000 - val_loss: 34049982464.0000\n",
      "Epoch 149/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 38841630720.0000 - val_loss: 34187497472.0000\n",
      "Epoch 150/150\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39507869696.0000 - val_loss: 34076008448.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x134eba650>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=30) # add a callback to prevent overfitting (but be very patient)\n",
    "model.fit(X_train_scaled, y_train, epochs=150, batch_size=32, validation_split=0.1, callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step - loss: 42128068608.0000\n",
      "Test loss: 42128068608.0\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the price of user input.\n",
    "Enter in the various attributes into the user_input array. The order is the order of the X data input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 119ms/step\n",
      "Estimated price: $975239.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "user_input = [3, 1.75, 3000, 30000, 2, 0, 0, 10, 7, 3000, 0, 2015]\n",
    "\n",
    "# Normalize the user input using the same scaler\n",
    "user_input_scaled = scaler.transform(np.array(user_input).reshape(1, -1))\n",
    "\n",
    "# Predict the price using the trained model\n",
    "predicted_price = model.predict(user_input_scaled)[0][0]\n",
    "\n",
    "print(f\"Estimated price: ${predicted_price:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
