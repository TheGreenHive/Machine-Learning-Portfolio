{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the data and drop any NA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
      "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
      "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
      "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./kc_house_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data = data.dropna(axis=0)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set y and X values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"price\"].astype(np.float32)\n",
    "data_prediction_features = [\"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\", \"floors\", \"waterfront\", \"view\", \"condition\", \"grade\", \"sqft_above\", \"sqft_basement\", \"yr_built\"]\n",
    "X = data[data_prediction_features].astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a test and train split 1:5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 10:27:10.238568: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4), # add various dropout layers to prevent overfitting\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Regression task, so no activation function (linear activation)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError() # mean squared error for regression task\n",
    "# ues adam optimizer function for dynamically updating gradient descent.\n",
    "optimizerFunction = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0005,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.995,\n",
    "    epsilon=5e-06,\n",
    "    amsgrad=True,\n",
    "    name='Adam',\n",
    ")\n",
    "model.compile(optimizer=optimizerFunction,\n",
    "              loss=loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/175\n",
      "487/487 [==============================] - 3s 3ms/step - loss: 240514809856.0000 - val_loss: 58922663936.0000\n",
      "Epoch 2/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 59379294208.0000 - val_loss: 44988715008.0000\n",
      "Epoch 3/175\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 50727362560.0000 - val_loss: 40117444608.0000\n",
      "Epoch 4/175\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 47259148288.0000 - val_loss: 38924005376.0000\n",
      "Epoch 5/175\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 45908623360.0000 - val_loss: 37579259904.0000\n",
      "Epoch 6/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 46508666880.0000 - val_loss: 37209845760.0000\n",
      "Epoch 7/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 45657362432.0000 - val_loss: 37040189440.0000\n",
      "Epoch 8/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 44357509120.0000 - val_loss: 37278580736.0000\n",
      "Epoch 9/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 44881506304.0000 - val_loss: 36572368896.0000\n",
      "Epoch 10/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 44843352064.0000 - val_loss: 37152989184.0000\n",
      "Epoch 11/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 43955810304.0000 - val_loss: 36448976896.0000\n",
      "Epoch 12/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 44511129600.0000 - val_loss: 36520243200.0000\n",
      "Epoch 13/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 43846660096.0000 - val_loss: 36080447488.0000\n",
      "Epoch 14/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43763216384.0000 - val_loss: 36082774016.0000\n",
      "Epoch 15/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43303387136.0000 - val_loss: 36263600128.0000\n",
      "Epoch 16/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 44245721088.0000 - val_loss: 35955421184.0000\n",
      "Epoch 17/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 43342524416.0000 - val_loss: 36444942336.0000\n",
      "Epoch 18/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 44255625216.0000 - val_loss: 36198813696.0000\n",
      "Epoch 19/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42898071552.0000 - val_loss: 35853787136.0000\n",
      "Epoch 20/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 43187109888.0000 - val_loss: 35685371904.0000\n",
      "Epoch 21/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43538247680.0000 - val_loss: 35746549760.0000\n",
      "Epoch 22/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42815156224.0000 - val_loss: 35581128704.0000\n",
      "Epoch 23/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 43230031872.0000 - val_loss: 35683586048.0000\n",
      "Epoch 24/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 44193599488.0000 - val_loss: 36030283776.0000\n",
      "Epoch 25/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42499727360.0000 - val_loss: 35615801344.0000\n",
      "Epoch 26/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41935081472.0000 - val_loss: 35744776192.0000\n",
      "Epoch 27/175\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 42146549760.0000 - val_loss: 35563048960.0000\n",
      "Epoch 28/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42765283328.0000 - val_loss: 35915583488.0000\n",
      "Epoch 29/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42437050368.0000 - val_loss: 36199882752.0000\n",
      "Epoch 30/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42454413312.0000 - val_loss: 35778117632.0000\n",
      "Epoch 31/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41443762176.0000 - val_loss: 35573264384.0000\n",
      "Epoch 32/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42156339200.0000 - val_loss: 35542392832.0000\n",
      "Epoch 33/175\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 42663297024.0000 - val_loss: 35352981504.0000\n",
      "Epoch 34/175\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 42044522496.0000 - val_loss: 35234168832.0000\n",
      "Epoch 35/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41875533824.0000 - val_loss: 35234062336.0000\n",
      "Epoch 36/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42476814336.0000 - val_loss: 35273203712.0000\n",
      "Epoch 37/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41873809408.0000 - val_loss: 35189608448.0000\n",
      "Epoch 38/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42302586880.0000 - val_loss: 35228626944.0000\n",
      "Epoch 39/175\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 41461489664.0000 - val_loss: 35283165184.0000\n",
      "Epoch 40/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42041630720.0000 - val_loss: 35178102784.0000\n",
      "Epoch 41/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41826697216.0000 - val_loss: 35527299072.0000\n",
      "Epoch 42/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41729093632.0000 - val_loss: 35323764736.0000\n",
      "Epoch 43/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42269712384.0000 - val_loss: 35057745920.0000\n",
      "Epoch 44/175\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 41741422592.0000 - val_loss: 35313766400.0000\n",
      "Epoch 45/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41742200832.0000 - val_loss: 35208007680.0000\n",
      "Epoch 46/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42464985088.0000 - val_loss: 35385577472.0000\n",
      "Epoch 47/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41613664256.0000 - val_loss: 35117592576.0000\n",
      "Epoch 48/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40700280832.0000 - val_loss: 35511836672.0000\n",
      "Epoch 49/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42249850880.0000 - val_loss: 35237916672.0000\n",
      "Epoch 50/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 42045898752.0000 - val_loss: 35442233344.0000\n",
      "Epoch 51/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41556226048.0000 - val_loss: 34975322112.0000\n",
      "Epoch 52/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40964042752.0000 - val_loss: 35171151872.0000\n",
      "Epoch 53/175\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 41545170944.0000 - val_loss: 35078004736.0000\n",
      "Epoch 54/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41500270592.0000 - val_loss: 34977951744.0000\n",
      "Epoch 55/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41667899392.0000 - val_loss: 35155451904.0000\n",
      "Epoch 56/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41537437696.0000 - val_loss: 35858718720.0000\n",
      "Epoch 57/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40626872320.0000 - val_loss: 35049123840.0000\n",
      "Epoch 58/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41219637248.0000 - val_loss: 35019821056.0000\n",
      "Epoch 59/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41009541120.0000 - val_loss: 35286462464.0000\n",
      "Epoch 60/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41455730688.0000 - val_loss: 34907410432.0000\n",
      "Epoch 61/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41627152384.0000 - val_loss: 35026804736.0000\n",
      "Epoch 62/175\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 41529344000.0000 - val_loss: 34893656064.0000\n",
      "Epoch 63/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41408557056.0000 - val_loss: 35112046592.0000\n",
      "Epoch 64/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41208045568.0000 - val_loss: 34996310016.0000\n",
      "Epoch 65/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41424109568.0000 - val_loss: 36330967040.0000\n",
      "Epoch 66/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41874534400.0000 - val_loss: 35123183616.0000\n",
      "Epoch 67/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39884288000.0000 - val_loss: 34839818240.0000\n",
      "Epoch 68/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41215062016.0000 - val_loss: 35244019712.0000\n",
      "Epoch 69/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40913293312.0000 - val_loss: 34874372096.0000\n",
      "Epoch 70/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41384103936.0000 - val_loss: 34692808704.0000\n",
      "Epoch 71/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40299274240.0000 - val_loss: 34926256128.0000\n",
      "Epoch 72/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40417636352.0000 - val_loss: 34936020992.0000\n",
      "Epoch 73/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41364574208.0000 - val_loss: 35012321280.0000\n",
      "Epoch 74/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40307814400.0000 - val_loss: 34999185408.0000\n",
      "Epoch 75/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40671932416.0000 - val_loss: 34785751040.0000\n",
      "Epoch 76/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41269518336.0000 - val_loss: 34907578368.0000\n",
      "Epoch 77/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40314142720.0000 - val_loss: 35155103744.0000\n",
      "Epoch 78/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40804376576.0000 - val_loss: 35047858176.0000\n",
      "Epoch 79/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41319120896.0000 - val_loss: 34674184192.0000\n",
      "Epoch 80/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40050225152.0000 - val_loss: 34725859328.0000\n",
      "Epoch 81/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40674684928.0000 - val_loss: 34677903360.0000\n",
      "Epoch 82/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40324169728.0000 - val_loss: 34748641280.0000\n",
      "Epoch 83/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39898169344.0000 - val_loss: 34825424896.0000\n",
      "Epoch 84/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40389799936.0000 - val_loss: 34987450368.0000\n",
      "Epoch 85/175\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 40519458816.0000 - val_loss: 34860765184.0000\n",
      "Epoch 86/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39768100864.0000 - val_loss: 34478051328.0000\n",
      "Epoch 87/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40858034176.0000 - val_loss: 34610696192.0000\n",
      "Epoch 88/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40542961664.0000 - val_loss: 35284590592.0000\n",
      "Epoch 89/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40014233600.0000 - val_loss: 34595012608.0000\n",
      "Epoch 90/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41186541568.0000 - val_loss: 34577272832.0000\n",
      "Epoch 91/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 41371574272.0000 - val_loss: 34814701568.0000\n",
      "Epoch 92/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39911952384.0000 - val_loss: 34400731136.0000\n",
      "Epoch 93/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40521441280.0000 - val_loss: 34591637504.0000\n",
      "Epoch 94/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40977457152.0000 - val_loss: 34771025920.0000\n",
      "Epoch 95/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40608587776.0000 - val_loss: 34468564992.0000\n",
      "Epoch 96/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40153784320.0000 - val_loss: 35690971136.0000\n",
      "Epoch 97/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40521375744.0000 - val_loss: 34568253440.0000\n",
      "Epoch 98/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40501460992.0000 - val_loss: 34964262912.0000\n",
      "Epoch 99/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40405225472.0000 - val_loss: 34424070144.0000\n",
      "Epoch 100/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40230281216.0000 - val_loss: 34555625472.0000\n",
      "Epoch 101/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40710287360.0000 - val_loss: 34298759168.0000\n",
      "Epoch 102/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40199102464.0000 - val_loss: 34415951872.0000\n",
      "Epoch 103/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40043749376.0000 - val_loss: 34390519808.0000\n",
      "Epoch 104/175\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 40849780736.0000 - val_loss: 34473676800.0000\n",
      "Epoch 105/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40170086400.0000 - val_loss: 34529599488.0000\n",
      "Epoch 106/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40224006144.0000 - val_loss: 34371006464.0000\n",
      "Epoch 107/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40400113664.0000 - val_loss: 34491400192.0000\n",
      "Epoch 108/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40323739648.0000 - val_loss: 34398928896.0000\n",
      "Epoch 109/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39929372672.0000 - val_loss: 34505224192.0000\n",
      "Epoch 110/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40009207808.0000 - val_loss: 34896797696.0000\n",
      "Epoch 111/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40320532480.0000 - val_loss: 34369671168.0000\n",
      "Epoch 112/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39664349184.0000 - val_loss: 34296565760.0000\n",
      "Epoch 113/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39771926528.0000 - val_loss: 34478858240.0000\n",
      "Epoch 114/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40117157888.0000 - val_loss: 34963578880.0000\n",
      "Epoch 115/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39394021376.0000 - val_loss: 34550734848.0000\n",
      "Epoch 116/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40534188032.0000 - val_loss: 34601635840.0000\n",
      "Epoch 117/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39325188096.0000 - val_loss: 34254684160.0000\n",
      "Epoch 118/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39717654528.0000 - val_loss: 34634760192.0000\n",
      "Epoch 119/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39933722624.0000 - val_loss: 34211620864.0000\n",
      "Epoch 120/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39825727488.0000 - val_loss: 34252427264.0000\n",
      "Epoch 121/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39986958336.0000 - val_loss: 34329915392.0000\n",
      "Epoch 122/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40422137856.0000 - val_loss: 34436595712.0000\n",
      "Epoch 123/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 38653964288.0000 - val_loss: 34320349184.0000\n",
      "Epoch 124/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39545090048.0000 - val_loss: 34388058112.0000\n",
      "Epoch 125/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 38797213696.0000 - val_loss: 34536148992.0000\n",
      "Epoch 126/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39795462144.0000 - val_loss: 34434846720.0000\n",
      "Epoch 127/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 38998716416.0000 - val_loss: 34305052672.0000\n",
      "Epoch 128/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40082776064.0000 - val_loss: 34414997504.0000\n",
      "Epoch 129/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39412424704.0000 - val_loss: 34390700032.0000\n",
      "Epoch 130/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39415820288.0000 - val_loss: 34217359360.0000\n",
      "Epoch 131/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39665201152.0000 - val_loss: 34192582656.0000\n",
      "Epoch 132/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 38836899840.0000 - val_loss: 34160502784.0000\n",
      "Epoch 133/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40086118400.0000 - val_loss: 34350327808.0000\n",
      "Epoch 134/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39677300736.0000 - val_loss: 34462441472.0000\n",
      "Epoch 135/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 38910955520.0000 - val_loss: 34648940544.0000\n",
      "Epoch 136/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 40440328192.0000 - val_loss: 34343653376.0000\n",
      "Epoch 137/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 38916370432.0000 - val_loss: 34251427840.0000\n",
      "Epoch 138/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39803244544.0000 - val_loss: 34144501760.0000\n",
      "Epoch 139/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 38978293760.0000 - val_loss: 34118283264.0000\n",
      "Epoch 140/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39003443200.0000 - val_loss: 34104096768.0000\n",
      "Epoch 141/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 38974099456.0000 - val_loss: 34207879168.0000\n",
      "Epoch 142/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39028764672.0000 - val_loss: 34390986752.0000\n",
      "Epoch 143/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 38859096064.0000 - val_loss: 34091511808.0000\n",
      "Epoch 144/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40288563200.0000 - val_loss: 34153836544.0000\n",
      "Epoch 145/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 38959038464.0000 - val_loss: 34149881856.0000\n",
      "Epoch 146/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 38873690112.0000 - val_loss: 34205769728.0000\n",
      "Epoch 147/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39872532480.0000 - val_loss: 34031390720.0000\n",
      "Epoch 148/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39380307968.0000 - val_loss: 34221066240.0000\n",
      "Epoch 149/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39565398016.0000 - val_loss: 33965930496.0000\n",
      "Epoch 150/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39374417920.0000 - val_loss: 34333005824.0000\n",
      "Epoch 151/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 38838415360.0000 - val_loss: 34139580416.0000\n",
      "Epoch 152/175\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 39074742272.0000 - val_loss: 33988026368.0000\n",
      "Epoch 153/175\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40085094400.0000 - val_loss: 34030276608.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1342f6a10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=30) # add a callback to prevent overfitting (but be very patient because of low processing time)\n",
    "model.fit(X_train_scaled, y_train, epochs=175, batch_size=32, validation_split=0.1, callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step - loss: 41965613056.0000\n",
      "Test loss: 41965613056.0\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the price of user input.\n",
    "Enter in the various attributes into the user_input array. The order is the order of the X data input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "Estimated price: $313654.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "user_input = [2, 0.75, 1020, 1076, 2, 0, 0, 3, 7, 1020, 0, 2008]\n",
    "\n",
    "# Normalize the user input using the same scaler\n",
    "user_input_scaled = scaler.transform(np.array(user_input).reshape(1, -1))\n",
    "\n",
    "# Predict the price using the trained model\n",
    "predicted_price = model.predict(user_input_scaled)[0][0]\n",
    "\n",
    "print(f\"Estimated price: ${predicted_price:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
