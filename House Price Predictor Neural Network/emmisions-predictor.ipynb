{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World countries CO2 emmission rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living',\n",
      "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
      "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
      "       'lat', 'long', 'sqft_living15', 'sqft_lot15'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./kc_house_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data = data.dropna(axis=0)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set y and X values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"price\"].astype(np.float32)\n",
    "data_prediction_features = [\"bedrooms\", \"bathrooms\", \"sqft_living\", \"sqft_lot\", \"floors\", \"waterfront\", \"view\", \"condition\", \"grade\", \"sqft_above\", \"sqft_basement\", \"yr_built\"]\n",
    "X = data[data_prediction_features].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 13:58:44.311192: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)  # Regression task, so no activation function\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "# ues adam optimizer function for dynamically updating gradient descent.\n",
    "optimizerFunction = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.995,\n",
    "    epsilon=5e-06,\n",
    "    amsgrad=True,\n",
    "    name='Adam',\n",
    ")\n",
    "model.compile(optimizer=optimizerFunction,\n",
    "              loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 186745700352.0000 - val_loss: 52004323328.0000\n",
      "Epoch 2/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 52189220864.0000 - val_loss: 40235589632.0000\n",
      "Epoch 3/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 47315804160.0000 - val_loss: 39804284928.0000\n",
      "Epoch 4/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 46262116352.0000 - val_loss: 37356437504.0000\n",
      "Epoch 5/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 45697384448.0000 - val_loss: 36765175808.0000\n",
      "Epoch 6/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 44851281920.0000 - val_loss: 36863528960.0000\n",
      "Epoch 7/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 44972736512.0000 - val_loss: 36534181888.0000\n",
      "Epoch 8/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 44375048192.0000 - val_loss: 36183543808.0000\n",
      "Epoch 9/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 44783046656.0000 - val_loss: 36091584512.0000\n",
      "Epoch 10/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 44142202880.0000 - val_loss: 36053811200.0000\n",
      "Epoch 11/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43516796928.0000 - val_loss: 36146343936.0000\n",
      "Epoch 12/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43335483392.0000 - val_loss: 35527053312.0000\n",
      "Epoch 13/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43136458752.0000 - val_loss: 35655659520.0000\n",
      "Epoch 14/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 42412724224.0000 - val_loss: 35550842880.0000\n",
      "Epoch 15/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 43161915392.0000 - val_loss: 36353945600.0000\n",
      "Epoch 16/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 43245977600.0000 - val_loss: 35671887872.0000\n",
      "Epoch 17/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 42875379712.0000 - val_loss: 35772694528.0000\n",
      "Epoch 18/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 42792001536.0000 - val_loss: 35460677632.0000\n",
      "Epoch 19/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 41535401984.0000 - val_loss: 35382022144.0000\n",
      "Epoch 20/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 43078524928.0000 - val_loss: 35591393280.0000\n",
      "Epoch 21/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 43138109440.0000 - val_loss: 35624202240.0000\n",
      "Epoch 22/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 41977884672.0000 - val_loss: 35325906944.0000\n",
      "Epoch 23/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 41345572864.0000 - val_loss: 35154493440.0000\n",
      "Epoch 24/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 41475674112.0000 - val_loss: 36069720064.0000\n",
      "Epoch 25/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41900466176.0000 - val_loss: 35079049216.0000\n",
      "Epoch 26/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 42509012992.0000 - val_loss: 35052822528.0000\n",
      "Epoch 27/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 42000117760.0000 - val_loss: 35091128320.0000\n",
      "Epoch 28/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 41510182912.0000 - val_loss: 35005706240.0000\n",
      "Epoch 29/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 41245388800.0000 - val_loss: 36019666944.0000\n",
      "Epoch 30/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 42473201664.0000 - val_loss: 35207639040.0000\n",
      "Epoch 31/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 42008993792.0000 - val_loss: 34868596736.0000\n",
      "Epoch 32/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 42160287744.0000 - val_loss: 35218751488.0000\n",
      "Epoch 33/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 42088398848.0000 - val_loss: 35089731584.0000\n",
      "Epoch 34/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 41122414592.0000 - val_loss: 34908065792.0000\n",
      "Epoch 35/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 40889491456.0000 - val_loss: 35387371520.0000\n",
      "Epoch 36/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 41972097024.0000 - val_loss: 34907553792.0000\n",
      "Epoch 37/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 41434836992.0000 - val_loss: 35007561728.0000\n",
      "Epoch 38/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41438482432.0000 - val_loss: 35556540416.0000\n",
      "Epoch 39/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41141424128.0000 - val_loss: 34606321664.0000\n",
      "Epoch 40/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40785170432.0000 - val_loss: 35447844864.0000\n",
      "Epoch 41/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 41136955392.0000 - val_loss: 34904195072.0000\n",
      "Epoch 42/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40283295744.0000 - val_loss: 35264716800.0000\n",
      "Epoch 43/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41888632832.0000 - val_loss: 34971795456.0000\n",
      "Epoch 44/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 40915722240.0000 - val_loss: 34514345984.0000\n",
      "Epoch 45/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 41144721408.0000 - val_loss: 34745151488.0000\n",
      "Epoch 46/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40470474752.0000 - val_loss: 34579156992.0000\n",
      "Epoch 47/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40207089664.0000 - val_loss: 34801897472.0000\n",
      "Epoch 48/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41696079872.0000 - val_loss: 34708074496.0000\n",
      "Epoch 49/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41207029760.0000 - val_loss: 34940067840.0000\n",
      "Epoch 50/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41068363776.0000 - val_loss: 34912497664.0000\n",
      "Epoch 51/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 40860356608.0000 - val_loss: 34818646016.0000\n",
      "Epoch 52/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41125687296.0000 - val_loss: 34649174016.0000\n",
      "Epoch 53/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41207099392.0000 - val_loss: 34875260928.0000\n",
      "Epoch 54/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 41359773696.0000 - val_loss: 34927091712.0000\n",
      "Epoch 55/100\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 40756830208.0000 - val_loss: 34563395584.0000\n",
      "Epoch 56/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39958396928.0000 - val_loss: 34888048640.0000\n",
      "Epoch 57/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40721076224.0000 - val_loss: 35233886208.0000\n",
      "Epoch 58/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40563302400.0000 - val_loss: 35132899328.0000\n",
      "Epoch 59/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40965062656.0000 - val_loss: 34982805504.0000\n",
      "Epoch 60/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40146067456.0000 - val_loss: 34933395456.0000\n",
      "Epoch 61/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40155664384.0000 - val_loss: 34991714304.0000\n",
      "Epoch 62/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39740051456.0000 - val_loss: 35621507072.0000\n",
      "Epoch 63/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40528764928.0000 - val_loss: 34627260416.0000\n",
      "Epoch 64/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40586407936.0000 - val_loss: 34967863296.0000\n",
      "Epoch 65/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40585515008.0000 - val_loss: 34718597120.0000\n",
      "Epoch 66/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40900096000.0000 - val_loss: 34635112448.0000\n",
      "Epoch 67/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40256032768.0000 - val_loss: 34339389440.0000\n",
      "Epoch 68/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40982499328.0000 - val_loss: 34459123712.0000\n",
      "Epoch 69/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40360869888.0000 - val_loss: 34763010048.0000\n",
      "Epoch 70/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39366418432.0000 - val_loss: 34429431808.0000\n",
      "Epoch 71/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40072462336.0000 - val_loss: 34601156608.0000\n",
      "Epoch 72/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40384946176.0000 - val_loss: 34508079104.0000\n",
      "Epoch 73/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40699478016.0000 - val_loss: 34203500544.0000\n",
      "Epoch 74/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39885950976.0000 - val_loss: 34426601472.0000\n",
      "Epoch 75/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40482271232.0000 - val_loss: 34473574400.0000\n",
      "Epoch 76/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40236597248.0000 - val_loss: 34269259776.0000\n",
      "Epoch 77/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40463499264.0000 - val_loss: 34562043904.0000\n",
      "Epoch 78/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39655858176.0000 - val_loss: 34649374720.0000\n",
      "Epoch 79/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40478572544.0000 - val_loss: 34440912896.0000\n",
      "Epoch 80/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40229437440.0000 - val_loss: 34782294016.0000\n",
      "Epoch 81/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39876640768.0000 - val_loss: 34260916224.0000\n",
      "Epoch 82/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39502323712.0000 - val_loss: 34273568768.0000\n",
      "Epoch 83/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 40227733504.0000 - val_loss: 35358797824.0000\n",
      "Epoch 84/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39570771968.0000 - val_loss: 34533847040.0000\n",
      "Epoch 85/100\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 39550898176.0000 - val_loss: 34709299200.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1314fa830>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=15)\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 945us/step - loss: 42195746816.0000\n",
      "Test loss: 42195746816.0\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Estimated price: $1062336.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "user_input = [3, 1.75, 3000, 30000, 2, 0, 0, 10, 7, 3000, 0, 2015]\n",
    "\n",
    "# Normalize the user input using the same scaler\n",
    "user_input_scaled = scaler.transform(np.array(user_input).reshape(1, -1))\n",
    "\n",
    "# Predict the price using the trained model\n",
    "predicted_price = model.predict(user_input_scaled)[0][0]\n",
    "\n",
    "print(f\"Estimated price: ${predicted_price:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
