{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.9.1\n"
     ]
    }
   ],
   "source": [
    "#!/usr/local/bin/python3.10\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.MaxPooling2D((2,2)),\n",
    "\n",
    "  tf.keras.layers.Dropout(0.5), \n",
    "  tf.keras.layers.Flatten(input_shape=(4, 4, 128)),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.4),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.1),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10065082, 0.09853759, 0.0982696 , 0.10095433, 0.09983879,\n",
       "        0.10025577, 0.0979636 , 0.09963704, 0.1022104 , 0.10168211]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10006502, 0.09985378, 0.09982701, 0.10009539, 0.09998379,\n",
       "        0.10002549, 0.09979648, 0.09996362, 0.10022119, 0.10016827]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.30233"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerFunction = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.995,\n",
    "    epsilon=5e-06,\n",
    "    amsgrad=True,\n",
    "    name='Adam',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizerFunction,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 106s 56ms/step - loss: 0.2437 - accuracy: 0.9289\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0855 - accuracy: 0.9768\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0627 - accuracy: 0.9833\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 89s 47ms/step - loss: 0.0514 - accuracy: 0.9860\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 89s 48ms/step - loss: 0.0456 - accuracy: 0.9883\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 79s 42ms/step - loss: 0.0375 - accuracy: 0.9895\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0333 - accuracy: 0.9908\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0336 - accuracy: 0.9908\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0277 - accuracy: 0.9918\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0258 - accuracy: 0.9926\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0248 - accuracy: 0.9924\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0238 - accuracy: 0.9933\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0213 - accuracy: 0.9941\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0198 - accuracy: 0.9943\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 82s 43ms/step - loss: 0.0175 - accuracy: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1548eab00>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=2)\n",
    "model.fit(x_train, y_train, epochs=15, batch_size=32, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 4s - loss: 0.0218 - accuracy: 0.9934 - 4s/epoch - 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.021769000217318535, 0.993399977684021]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[0.08533674, 0.08533674, 0.08533674, 0.08533674, 0.08533674,\n",
       "        0.08533674, 0.08533674, 0.23196931, 0.08533674, 0.08533674],\n",
       "       [0.08533674, 0.08533674, 0.23196931, 0.08533674, 0.08533674,\n",
       "        0.08533674, 0.08533674, 0.08533674, 0.08533674, 0.08533674],\n",
       "       [0.08533675, 0.23196931, 0.08533675, 0.08533675, 0.08533675,\n",
       "        0.08533675, 0.08533675, 0.08533675, 0.08533677, 0.08533675],\n",
       "       [0.23196931, 0.08533674, 0.08533674, 0.08533674, 0.08533674,\n",
       "        0.08533674, 0.08533674, 0.08533674, 0.08533674, 0.08533674],\n",
       "       [0.08533689, 0.08533689, 0.08533689, 0.08533689, 0.231967  ,\n",
       "        0.08533689, 0.08533689, 0.08533689, 0.08533689, 0.08533788]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist_predictor.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 24, 24, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 664,138\n",
      "Trainable params: 663,818\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x154e95cf0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "[[1.7119652e-06 9.9889970e-01 4.1529401e-07 3.7837009e-09 1.5894165e-04\n",
      "  1.1568522e-06 2.4681940e-06 7.6684472e-04 1.3316088e-04 3.5623962e-05]]\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('mnist_predictor.h5')\n",
    "\n",
    "new_model.summary()\n",
    "\n",
    "input_image = np.ones((28, 28, 1))  # Replace this with your actual image data\n",
    "\n",
    "# Preprocess the image data (optional, depending on how you trained the model)\n",
    "# input_image = preprocess(input_image)\n",
    "\n",
    "# Expand the dimensions to match the expected shape (batch_size, 28, 28, 1)\n",
    "input_image = np.expand_dims(input_image, axis=0)\n",
    "\n",
    "# Make predictions\n",
    "predictions = new_model.predict(input_image)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
